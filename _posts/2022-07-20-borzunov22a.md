---
title: Training Transformers Together
abstract: The infrastructure necessary for training state-of-the-art models is becoming
  overly expensive, which makes training such models affordable only to large corporations
  and institutions. Recent work proposes several methods for training such models
  collaboratively, i.e., by pooling together hardware from many independent parties
  and training a shared model over the Internet. In this demonstration, we collaboratively
  trained a text-to-image transformer similar to OpenAI DALL-E. We invited the viewers
  to join the ongoing training run, showing them instructions on how to contribute
  using the available hardware. We explained how to address the engineering challenges
  associated with such a training run (slow communication, limited memory, uneven
  performance between devices, and security concerns) and discussed how the viewers
  can set up collaborative training runs themselves. Finally, we show that the resulting
  model generates images of reasonable quality on a number of prompts.
section: Demonstrations
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: borzunov22a
month: 0
tex_title: Training Transformers Together
firstpage: 335
lastpage: 342
page: 335-342
order: 335
cycles: false
bibtex_author: Borzunov, Alexander and Ryabinin, Max and Dettmers, Tim and Lhoest,
  Quentin and Saulnier, Lucile and Diskin, Michael and Jernite, Yacine
author:
- given: Alexander
  family: Borzunov
- given: Max
  family: Ryabinin
- given: Tim
  family: Dettmers
- given: Quentin
  family: Lhoest
- given: Lucile
  family: Saulnier
- given: Michael
  family: Diskin
- given: Yacine
  family: Jernite
date: 2022-07-20
address:
container-title: Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track
volume: '176'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 7
  - 20
pdf: https://proceedings.mlr.press/v176/borzunov22a/borzunov22a.pdf
extras:
- label: Supplementary PDF
  link: https://proceedings.mlr.press/v176/borzunov22a/borzunov22a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
