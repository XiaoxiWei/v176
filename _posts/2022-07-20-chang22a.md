---
title: 'WebQA: A Multimodal Multihop NeurIPS Challenge'
abstract: 'Scaling the current QA formulation to the open-domain and multi-hop nature
  of web searches requires fundamental advances in visual representation learning,
  multimodal reasoning and language generation. To facilitate research at this intersection,
  we propose WebQA challenge that mirrors the way humans use the web: 1) Ask a question,
  2) Choose sources to aggregate, and 3) Produce a fluent language response. Our challenge
  for the community is to create unified multimodal reasoning models that can answer
  questions regardless of the source modality, moving us closer to digital assistants
  that search through not only text-based knowledge, but also the richer visual trove
  of information.'
section: Competitions
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chang22a
month: 0
tex_title: 'WebQA: A Multimodal Multihop NeurIPS Challenge'
firstpage: 232
lastpage: 245
page: 232-245
order: 232
cycles: false
bibtex_author: Chang, Yingshan and Bisk, Yonatan
author:
- given: Yingshan
  family: Chang
- given: Yonatan
  family: Bisk
date: 2022-07-20
address:
container-title: Proceedings of the NeurIPS 2021 Competitions and Demonstrations Track
volume: '176'
genre: inproceedings
issued:
  date-parts:
  - 2022
  - 7
  - 20
pdf: https://proceedings.mlr.press/v176/chang22a/chang22a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
